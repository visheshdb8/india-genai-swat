{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07329c73-14a8-4b58-bd80-e710dccc15ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "height": 47
   },
   "outputs": [],
   "source": [
    "%pip install -U openai gradio\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d7cc9a4-3b0b-497c-8f99-bcd5caf28f22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import sys\n",
    "import utils\n",
    "import gradio as gr\n",
    "\n",
    "sys.path.append('/Workspace/Users/vishesh.arya@databricks.com/india-genai-swat/cx-support-chatbot')\n",
    "DATABRICKS_TOKEN = dbutils.secrets.get(scope = \"db-field-eng\", key = \"va-pat-token\")\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=\"https://e2-demo-field-eng.cloud.databricks.com/serving-endpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d304e78a-0ced-4e1f-a8fa-9ced8416b4ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=\"va_ext_azure_openai_gpt35\", temperature = 0, max_tokens = 2000):\n",
    "  completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature = temperature,\n",
    "    max_tokens=max_tokens,\n",
    "  )\n",
    "  \n",
    "  return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "134c3c5c-cf84-413d-8fff-bf92d06d9082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### System of chained prompts for processing the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b2d15a3-3929-439f-bef1-b569840d22d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "def process_user_message(user_input, all_messages=[], debug=True):\n",
    "  delimiter = \"```\"\n",
    "\n",
    "  category_and_product_response = utils.find_category_and_product_only(user_input, utils.get_products_and_category())\n",
    "  \n",
    "  # Step 1: Extract the list of products\n",
    "  category_and_product_list = utils.read_string_to_list(category_and_product_response)\n",
    "  if debug: print(\"Step 1: Extracted list of products.\")\n",
    "    \n",
    "  # Step 2: If products are found, look them up\n",
    "  product_information = utils.generate_output_string(category_and_product_list)\n",
    "  if debug: print(\"Step 2: Looked up product information.\")\n",
    "  \n",
    "  # Step 3: Answer the user question\n",
    "  \n",
    "  system_message = f\"\"\"You are a customer service assistant for a large electronic store. You take in user's questions, delimited by triple backticks (```) and respond in a friendly and helpful tone, with concise answers. Make sure to ask the user relevant follow-up questions. Do not respond to any user questions not related to the context provided under `Relevant product information`\"\"\"\n",
    "  \n",
    "  messages = [\n",
    "    {'role': 'system', 'content': system_message},\n",
    "    {'role': 'user', 'content': f\"{delimiter}{user_input}{delimiter}. Relevant product information:\\n{product_information}\"},\n",
    "    ]\n",
    "  \n",
    "  final_response = get_completion_from_messages(all_messages + messages)\n",
    "  if debug: print(\"Step 3: Generated response to user question.\")\n",
    "\n",
    "  # Step 4: Ask the model if the response answers the initial user query well\n",
    "  user_message = f\"\"\"\n",
    "  Customer message: {delimiter}{user_input}{delimiter}\n",
    "  Agent response: {delimiter}{final_response}{delimiter}\n",
    "  \n",
    "  You are a customer service assistant for a large electronic store. Does the response sufficiently answer the question and is based on the context provided under `Relevant product information`?\\n\n",
    "  Relevant product information:\\n{product_information}\n",
    "  \n",
    "  Respond only with Y or N\n",
    "  \"\"\"\n",
    "  \n",
    "  messages = [\n",
    "    {'role': 'system', 'content': system_message},\n",
    "    {'role': 'user', 'content': user_message}\n",
    "    ]\n",
    "  \n",
    "  evaluation_response = get_completion_from_messages(messages)\n",
    "  if debug: print(\"Step 4: Model evaluated the response.\")\n",
    "\n",
    "  # Step 5: If yes, use this answer; if not, say that you will connect the user to a human\n",
    "  if \"Y\" in evaluation_response:  # Using \"in\" instead of \"==\" to be safer for model output variation (e.g., \"Y.\" or \"Yes\")\n",
    "    if debug: print(\"Step 5: Model approved the response.\")\n",
    "    return final_response\n",
    "  else:\n",
    "    if debug: print(\"Step 5: Model disapproved the response.\")\n",
    "    neg_str = \"I'm unable to provide the information you're looking for. I'll connect you with a human representative for further assistance.\"\n",
    "    return neg_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "952f54e8-d6ad-4a84-b256-a49379270362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "delimiter = \"```\"\n",
    "\n",
    "def collect_messages(prompt, history):\n",
    "  global context\n",
    "  \n",
    "  if not history:\n",
    "    context = []\n",
    "  \n",
    "  context.append({'role': 'user', 'content': f\"{delimiter}{prompt}{delimiter}\"})\n",
    "\n",
    "  try:\n",
    "    response = process_user_message(user_input=prompt, all_messages=context, debug=False)\n",
    "  except Exception as e:\n",
    "    error_msg = eval(str(e).split(\" - \", 1)[1]) if \" - \" in str(e) else str(e)\n",
    "    \n",
    "    if 'external_model_message' in error_msg:\n",
    "      response = error_msg['external_model_message']['error']['message']\n",
    "    elif 'input_guardrail' in error_msg:\n",
    "      response = error_msg['input_guardrail'][0]\n",
    "    elif 'output_guardrail' in error_msg:\n",
    "      response = error_msg['output_guardrail'][0]\n",
    "    else:\n",
    "      response = \"I'm unable to provide the information you're looking for. I'll connect you with a human representative for further assistance.\"\n",
    "  \n",
    "  context.append({'role': 'assistant', 'content': response})\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "202946c1-3364-4b15-bda9-d5a2197b1ae9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "demo = gr.ChatInterface(\n",
    "    collect_messages,\n",
    "    type=\"messages\",\n",
    "    textbox=gr.Textbox(placeholder=\"Hi, How can I help you today?\", container=False, scale=7),\n",
    "    title=\"Customer Support Chatbot\",\n",
    "    description=\"This chatbot is a demo example of a customer support chatbot for an electronic store\",\n",
    "    examples=[\n",
    "        \"What TV do you have?\",\n",
    "        \"Which is the cheapest?\",\n",
    "        \"Which is the most expensive?\",\n",
    "        \"Tell me about all of its features\",\n",
    "        \"Give me comparison of features for the cheapest vs most expensive option in a table format\"\n",
    "    ],\n",
    "    cache_examples=False,\n",
    ")\n",
    "\n",
    "demo.launch(share=True, debug=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "cx-support-chatbot",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
