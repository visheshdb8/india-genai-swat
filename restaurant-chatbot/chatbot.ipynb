{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30122e0b-a333-4746-af0c-845ecb0655f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Chat Completions\n",
    "\n",
    "In this notebook, we will explore how we can utilize the chat format to have extended conversations with chatbots personalized or specialized for specific tasks or behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "364ca9d6-1cba-4c8a-a3cd-caf7969d7f61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U openai gradio\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a16b8ebe-319c-4b34-aac7-a2d8bed7b958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f4bbf61-87a6-4818-841d-77ba2baefc0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DATABRICKS_TOKEN = dbutils.secrets.get(scope = \"db-field-eng\", key = \"va-pat-token\")\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=\"https://e2-demo-field-eng.cloud.databricks.com/serving-endpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efc10dc6-3387-401c-8691-1587cc884e74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Helper Functions\n",
    "In this new helper function, we're going to pass in a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc73148a-d283-4117-b585-f54a7b89017c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=\"va_ext_azure_openai_gpt35\", temperature = 0):\n",
    "  completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature = temperature, # this sets the degree of randomness of the model's output and allows it to be more creative or less deterministic\n",
    "    max_tokens=2000, # sets max number of tokens for output response\n",
    "  )\n",
    "  \n",
    "  return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebde91ce-1cd3-458b-b693-d35da3cc3ac6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Testing helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10a93f36-e8f8-4e8e-b691-e279f5d6e033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},    \n",
    "{'role':'user', 'content':'tell me a joke'},   \n",
    "{'role':'assistant', 'content':'Why did the chicken cross the road'},   \n",
    "{'role':'user', 'content':'I don\\'t know'}  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69fb0e5a-ece2-4e94-9e4a-ef051be573f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response = get_completion_from_messages(messages, temperature = 1) # we are using a higher temperature for creative jokes\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91edfe1f-0f15-4ba3-8dc5-b0868a0b4350",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Each conversation with the language model is a standalone interaction so we must provide all conversation history and relevant messages as context for the model to draw from in the current conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ec131ce-2463-4b0b-8c41-2f8a3850a8a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},    \n",
    "{'role':'user', 'content':'Hi, my name is Vicky'}  ]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature = 1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "041e96a0-b3eb-4b6b-908f-ece02fb7b1c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},    \n",
    "{'role':'user', 'content':'Yes,  can you remind me, What is my name?'}  ]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95f6cb9e-b6c5-495f-ad4c-8d9be5ac2362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},\n",
    "{'role':'user', 'content':'Hi, my name is Vicky'},\n",
    "{'role':'assistant', 'content': 'Hello Vicky! It\\'s nice to meet you. How can I assist you today?'},\n",
    "{'role':'user', 'content':'Yes, you can remind me, What is my name?'}  ]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature = 1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f37e418c-8f24-4c03-9f09-71dc02c7ac1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Order Bot\n",
    "We can automate the collection of user prompts and assistant responses to build an Order Bot. The OrderBot will take orders at a pizza restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63759920-5d3c-4b0e-beb1-57e13ecf854f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Context for the chatbot\n",
    "context = [{'role': 'system', 'content': \"\"\"\n",
    "You are OrderBot, an automated service to collect orders for a fast food chain restaurant.\n",
    "\n",
    "** You first greet the customer and show them a brief overview of mains (pizzas) in our menu\n",
    "\n",
    "** You wait to collect the entire order, then summarize it and check for a final time if the customer wants to add anything else. While collecting the order, you can recommend some other options on the menu (along with their sizes) that you would recommend with the items in the order.\n",
    "\n",
    "** You then ask if it's a pickup or delivery. Finally, perform the calculations carefully step-by-step and add 10 % tax to get to the order total. Show that amount along with an order summary along with your calculations.\n",
    "\n",
    "# Ensure to ask the address if it's a delivery. For pickups, ask the customer to collect the order from Shop-1, Hiranandani Gardens, Powai in 30 minutes.\n",
    "# Make sure to clarify all options, extras, and sizes to uniquely identify the item from the menu.\n",
    "# Respond with `As an order bot, I cannot assist with that` for anything that is not related to the food delivery service for your restaurant.\n",
    "# You respond in a short, very conversational friendly style and do not ask multiple questions at a time or suggest multiple options at a time\n",
    "\n",
    "The menu includes:\n",
    "- pepperoni pizza  12.95, 10.00, 7.00\n",
    "- cheese pizza   10.95, 9.25, 6.50\n",
    "- eggplant pizza   11.95, 9.75, 6.75\n",
    "- fries 4.50, 3.50\n",
    "- greek salad 7.25\n",
    "- Toppings:\n",
    "  a. extra cheese 2.00\n",
    "  b. mushrooms 1.50\n",
    "  c. sausage 3.00\n",
    "  d. canadian bacon 3.50\n",
    "  e. AI sauce 1.50\n",
    "  f. peppers 1.00\n",
    "- Drinks:\n",
    "  a. coke 3.00, 2.00, 1.00\n",
    "  b. sprite 3.00, 2.00, 1.00\n",
    "  c. bottled water 5.00\n",
    "\"\"\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf4ffbbb-eaeb-449c-bf69-17c4495560f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to process the conversation\n",
    "def collect_messages(prompt, history):\n",
    "  context.append({'role': 'user', 'content': prompt})\n",
    "  response = get_completion_from_messages(context, model=\"va_ext_azure_openai\", temperature=0)\n",
    "  context.append({'role': 'assistant', 'content': response})\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "084cd07a-a03e-42ca-8432-b5a6eb9144ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "demo = gr.ChatInterface(\n",
    "    collect_messages,\n",
    "    type=\"messages\",\n",
    "    textbox=gr.Textbox(placeholder=\"I would like to order something today\", container=False, scale=7),\n",
    "    title=\"Order Bot\",\n",
    "    description=\"This chatbot is a demo example of an order bot for a fast food chain\",\n",
    "    cache_examples=False,\n",
    ")\n",
    "\n",
    "demo.launch(share=True, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "691e5c38-2ec2-423a-9aac-ee54d838e9ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Finally we can create an order JSON summary to send to our order system. We'll use temperature = 0 here as we want these tasks to be very predictable to avoid downstream failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "729250a5-584b-448b-982c-419cdecee021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = [{'role':'user', 'content':f\"\"\"create a json summary of the previous food order, delimited by ```. Extract the following information from the order summary:\n",
    "1) pizza, include size\n",
    "2) list of toppings\n",
    "3) list of drinks, include size\n",
    "4) list of sides include size\n",
    "5) total price \n",
    "\n",
    "Order summary:\n",
    "```{context}```\n",
    "\n",
    "Ensure to add pricing for each line item. Only have final numbers and don't include expressions for prices\n",
    "\n",
    "Example output:\n",
    "```\n",
    "{{\"pizza\": {{\"type\": \"cheese\", \"size\": \"large\", \"toppings\": [\"mushrooms\", \"extra cheese\"], \"price\": 13.95}}, \"drinks\": [{{\"type\": \"coke\", \"size\": \"medium\", \"price\": 2.00}}], \"sides\": [{{\"type\": \"fries\", \"size\": \"medium\", \"price\": 3.50}}], \"base_price\": 20.45, \"tax_perc\": 10.00, \"total_price\": 22.495}}```\n",
    "\"\"\"}]\n",
    "\n",
    "response = get_completion_from_messages(prompt, model=\"databricks-meta-llama-3-1-70b-instruct\", temperature = 0)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "chatbot",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
